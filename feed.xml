<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://edypidy.github.io/studyblog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://edypidy.github.io/studyblog/" rel="alternate" type="text/html" /><updated>2021-09-26T12:30:54-05:00</updated><id>https://edypidy.github.io/studyblog/feed.xml</id><title type="html">개구리의 우물 탈출기</title><subtitle>An easy to use blogging platform with support for Jupyter Notebooks.</subtitle><entry><title type="html">Heart Desease 데이터 셋 분석과 train_test split에 따른 Accuracy</title><link href="https://edypidy.github.io/studyblog/kaggle/heart%20desease/jupyter/classification/xgboost/adaboost/lgbm/logistic%20regression/randomforest/mlpclassifier/2021/09/25/kaggle_study-_Heart_Attack_Analysis_&_Prediction_Dataset.html" rel="alternate" type="text/html" title="Heart Desease 데이터 셋 분석과 train_test split에 따른 Accuracy" /><published>2021-09-25T00:00:00-05:00</published><updated>2021-09-25T00:00:00-05:00</updated><id>https://edypidy.github.io/studyblog/kaggle/heart%20desease/jupyter/classification/xgboost/adaboost/lgbm/logistic%20regression/randomforest/mlpclassifier/2021/09/25/-%5Bkaggle_study%5D_Heart_Attack_Analysis_&amp;_Prediction_Dataset</id><author><name>Daniel Lee - edypidy</name></author><category term="kaggle" /><category term="heart desease" /><category term="jupyter" /><category term="classification" /><category term="XGboost" /><category term="AdaBoost" /><category term="Lgbm" /><category term="Logistic Regression" /><category term="RandomForest" /><category term="MLPClassifier" /><summary type="html"></summary></entry><entry><title type="html">[ML] SVM, Kernel-SVM with Gaussian-rbf kernel와 기본적인 하이퍼파라미터들</title><link href="https://edypidy.github.io/studyblog/jupyter/svm/kernel-svm/classifying/hyper-lane/kernel/gaussian-rbf/2021/09/25/_SVM(%EC%B5%9C%EC%A2%85).html" rel="alternate" type="text/html" title="[ML] SVM, Kernel-SVM with Gaussian-rbf kernel와 기본적인 하이퍼파라미터들" /><published>2021-09-25T00:00:00-05:00</published><updated>2021-09-25T00:00:00-05:00</updated><id>https://edypidy.github.io/studyblog/jupyter/svm/kernel-svm/classifying/hyper-lane/kernel/gaussian-rbf/2021/09/25/_SVM(%EC%B5%9C%EC%A2%85)</id><author><name>Daniel Lee - pidyology</name></author><category term="jupyter" /><category term="SVM" /><category term="Kernel-SVM" /><category term="classifying" /><category term="hyper-lane" /><category term="kernel" /><category term="gaussian-rbf" /><summary type="html"></summary></entry><entry><title type="html">[ML]로지스틱 회귀 유도 및 scikit-learn api 맛보기</title><link href="https://edypidy.github.io/studyblog/jupyter/logistic%20regression/classifying/loss%20function/2021/09/25/_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80.html" rel="alternate" type="text/html" title="[ML]로지스틱 회귀 유도 및 scikit-learn api 맛보기" /><published>2021-09-25T00:00:00-05:00</published><updated>2021-09-25T00:00:00-05:00</updated><id>https://edypidy.github.io/studyblog/jupyter/logistic%20regression/classifying/loss%20function/2021/09/25/_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80</id><author><name>Daniel Lee - pidyology</name></author><category term="jupyter" /><category term="logistic regression" /><category term="classifying" /><category term="loss function" /><summary type="html"></summary></entry></feed>